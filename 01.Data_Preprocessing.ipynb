{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Libraries to import:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(365)\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('display.max_rows', 1000)"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1604905232712
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading in datasets from June 2019 to June 2020"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Reading in dataset for January for yellow cabs\n",
        "\n",
        "#june_2019_df = pd.read_csv('./data/original_data/yellow_2019-06.csv')\n",
        "#july_2019_df = pd.read_csv('./data/original_data/yellow_2019-07.csv')\n",
        "#august_2019_df = pd.read_csv('./data/original_data/yellow_2019-08.csv')\n",
        "#september_2019_df = pd.read_csv('./data/original_data/yellow_2019-09.csv')\n",
        "#october_2019_df = pd.read_csv('./data/original_data/yellow_2019-10.csv')\n",
        "#november_2019_df = pd.read_csv('./data/original_data/yellow_2019-11.csv')\n",
        "#december_2019_df = pd.read_csv('./data/original_data/yellow_2019-12.csv')\n",
        "\n",
        "\n",
        "jan_2020_df = pd.read_csv('./data/original_data/yellow_2020-01.csv')\n",
        "feb_2020_df = pd.read_csv('./data/original_data/yellow_2020-02.csv')\n",
        "#march_2020_df = pd.read_csv('./data/original_data/yellow_2020-03.csv')\n",
        "#april_2020_df = pd.read_csv('./data/original_data/yellow_2020-04.csv')\n",
        "#may_2020_df = pd.read_csv('./data/original_data/yellow_2020-05.csv')\n",
        "#june_2020_df = pd.read_csv('./data/original_data/yellow_2020-06.csv')"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604903549169
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "borough_info = pd.read_csv('./data/taxi_zones/taxi_zones.csv')\n",
        "borough_info.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "   LocationID        Borough                     Zone service_zone\n0           1            EWR           Newark Airport          EWR\n1           2         Queens              Jamaica Bay    Boro Zone\n2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n3           4      Manhattan            Alphabet City  Yellow Zone\n4           5  Staten Island            Arden Heights    Boro Zone",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LocationID</th>\n      <th>Borough</th>\n      <th>Zone</th>\n      <th>service_zone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>EWR</td>\n      <td>Newark Airport</td>\n      <td>EWR</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Queens</td>\n      <td>Jamaica Bay</td>\n      <td>Boro Zone</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Bronx</td>\n      <td>Allerton/Pelham Gardens</td>\n      <td>Boro Zone</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Manhattan</td>\n      <td>Alphabet City</td>\n      <td>Yellow Zone</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Staten Island</td>\n      <td>Arden Heights</td>\n      <td>Boro Zone</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604902086554
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Let's see how our dataset look like after being sorted on pickup time. We will use year 2020 and January as an example"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jan_2020_df['tpep_pickup_datetime'].sort_values()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "782435     2003-01-01 00:07:17\n5086498    2008-12-31 23:02:40\n1447622    2008-12-31 23:02:50\n5086894    2008-12-31 23:03:44\n3073519    2008-12-31 23:03:48\n                  ...         \n4269480    2020-07-10 11:34:11\n4282277    2020-07-31 18:50:41\n275044     2021-01-02 00:22:00\n275045     2021-01-02 00:44:08\n275046     2021-01-02 01:12:10\nName: tpep_pickup_datetime, Length: 6405008, dtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604903456513
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though this should have only January of 2020 information, we can see that some years range from 203 to 2021. Definitely should do data cleaning."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Create function that correctly assigns borough names to 'PULocationID'."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_borough(df, borough_info):\n",
        "    conditions = [\n",
        "        df['PULocationID'].eq(2)|df['PULocationID'].eq(7)|df['PULocationID'].eq(8)|df['PULocationID'].eq(9)|df['PULocationID'].eq(10)|df['PULocationID'].eq(15)|df['PULocationID'].eq(16)|df['PULocationID'].eq(19)|df['PULocationID'].eq(27)|df['PULocationID'].eq(28)|df['PULocationID'].eq(30)|df['PULocationID'].eq(38)|df['PULocationID'].eq(53)|df['PULocationID'].eq(56)|df['PULocationID'].eq(57)|df['PULocationID'].eq(64)|df['PULocationID'].eq(70)|df['PULocationID'].eq(73)|df['PULocationID'].eq(82)|df['PULocationID'].eq(83)|df['PULocationID'].eq(86)|df['PULocationID'].eq(92)|df['PULocationID'].eq(93)|df['PULocationID'].eq(95)|df['PULocationID'].eq(96)|df['PULocationID'].eq(98)|df['PULocationID'].eq(101)|df['PULocationID'].eq(102)|df['PULocationID'].eq(117)|df['PULocationID'].eq(121)|df['PULocationID'].eq(122)|df['PULocationID'].eq(124)|df['PULocationID'].eq(129)|df['PULocationID'].eq(130)|df['PULocationID'].eq(131)|df['PULocationID'].eq(132)|df['PULocationID'].eq(134)|df['PULocationID'].eq(135)|df['PULocationID'].eq(138)|df['PULocationID'].eq(139)|df['PULocationID'].eq(145)|df['PULocationID'].eq(146)|df['PULocationID'].eq(157)|df['PULocationID'].eq(160)|df['PULocationID'].eq(171)|df['PULocationID'].eq(173)|df['PULocationID'].eq(175)|df['PULocationID'].eq(179)|df['PULocationID'].eq(180)|df['PULocationID'].eq(191)|df['PULocationID'].eq(192)|df['PULocationID'].eq(193)|df['PULocationID'].eq(196)|df['PULocationID'].eq(197)|df['PULocationID'].eq(198)|df['PULocationID'].eq(201)|df['PULocationID'].eq(203)|df['PULocationID'].eq(205)|df['PULocationID'].eq(207)|df['PULocationID'].eq(215)|df['PULocationID'].eq(216)|df['PULocationID'].eq(218)|df['PULocationID'].eq(219)|df['PULocationID'].eq(223)|df['PULocationID'].eq(226)|df['PULocationID'].eq(252)|df['PULocationID'].eq(253)|df['PULocationID'].eq(258)|df['PULocationID'].eq(260),\n",
        "        df['PULocationID'].eq(3)|df['PULocationID'].eq(18)|df['PULocationID'].eq(20)|df['PULocationID'].eq(31)|df['PULocationID'].eq(32)|df['PULocationID'].eq(46)|df['PULocationID'].eq(47)|df['PULocationID'].eq(51)|df['PULocationID'].eq(58)|df['PULocationID'].eq(59)|df['PULocationID'].eq(60)|df['PULocationID'].eq(69)|df['PULocationID'].eq(78)|df['PULocationID'].eq(81)|df['PULocationID'].eq(94)|df['PULocationID'].eq(119)|df['PULocationID'].eq(126)|df['PULocationID'].eq(136)|df['PULocationID'].eq(147)|df['PULocationID'].eq(159)|df['PULocationID'].eq(167)|df['PULocationID'].eq(168)|df['PULocationID'].eq(169)|df['PULocationID'].eq(174)|df['PULocationID'].eq(182)|df['PULocationID'].eq(183)|df['PULocationID'].eq(184)|df['PULocationID'].eq(185)|df['PULocationID'].eq(199)|df['PULocationID'].eq(200)|df['PULocationID'].eq(208)|df['PULocationID'].eq(212)|df['PULocationID'].eq(213)|df['PULocationID'].eq(220)|df['PULocationID'].eq(235)|df['PULocationID'].eq(240)|df['PULocationID'].eq(241)|df['PULocationID'].eq(242)|df['PULocationID'].eq(247)|df['PULocationID'].eq(248)|df['PULocationID'].eq(250)|df['PULocationID'].eq(254)|df['PULocationID'].eq(259),\n",
        "        df['PULocationID'].eq(4)|df['PULocationID'].eq(12)|df['PULocationID'].eq(13)|df['PULocationID'].eq(24)|df['PULocationID'].eq(41)|df['PULocationID'].eq(42)|df['PULocationID'].eq(43)|df['PULocationID'].eq(45)|df['PULocationID'].eq(48)|df['PULocationID'].eq(50)|df['PULocationID'].eq(68)|df['PULocationID'].eq(74)|df['PULocationID'].eq(75)|df['PULocationID'].eq(79)|df['PULocationID'].eq(87)|df['PULocationID'].eq(88)|df['PULocationID'].eq(90)|df['PULocationID'].eq(100)|df['PULocationID'].eq(103)|df['PULocationID'].eq(104)|df['PULocationID'].eq(105)|df['PULocationID'].eq(107)|df['PULocationID'].eq(113)|df['PULocationID'].eq(114)|df['PULocationID'].eq(116)|df['PULocationID'].eq(120)|df['PULocationID'].eq(125)|df['PULocationID'].eq(127)|df['PULocationID'].eq(128)|df['PULocationID'].eq(137)|df['PULocationID'].eq(140)|df['PULocationID'].eq(141)|df['PULocationID'].eq(142)|df['PULocationID'].eq(143)|df['PULocationID'].eq(144)|df['PULocationID'].eq(148)|df['PULocationID'].eq(151)|df['PULocationID'].eq(152)|df['PULocationID'].eq(153)|df['PULocationID'].eq(158)|df['PULocationID'].eq(161)|df['PULocationID'].eq(162)|df['PULocationID'].eq(163)|df['PULocationID'].eq(164)|df['PULocationID'].eq(166)|df['PULocationID'].eq(170)|df['PULocationID'].eq(186)|df['PULocationID'].eq(194)|df['PULocationID'].eq(202)|df['PULocationID'].eq(209)|df['PULocationID'].eq(211)|df['PULocationID'].eq(224)|df['PULocationID'].eq(229)|df['PULocationID'].eq(230)|df['PULocationID'].eq(231)|df['PULocationID'].eq(232)|df['PULocationID'].eq(233)|df['PULocationID'].eq(234)|df['PULocationID'].eq(236)|df['PULocationID'].eq(237)|df['PULocationID'].eq(238)|df['PULocationID'].eq(239)|df['PULocationID'].eq(243)|df['PULocationID'].eq(244)|df['PULocationID'].eq(246)|df['PULocationID'].eq(249)|df['PULocationID'].eq(261)|df['PULocationID'].eq(262)|df['PULocationID'].eq(263),\n",
        "        df['PULocationID'].eq(5)|df['PULocationID'].eq(6)|df['PULocationID'].eq(23)|df['PULocationID'].eq(44)|df['PULocationID'].eq(84)|df['PULocationID'].eq(99)|df['PULocationID'].eq(109)|df['PULocationID'].eq(110)|df['PULocationID'].eq(115)|df['PULocationID'].eq(118)|df['PULocationID'].eq(156)|df['PULocationID'].eq(172)|df['PULocationID'].eq(176)|df['PULocationID'].eq(187)|df['PULocationID'].eq(204)|df['PULocationID'].eq(206)|df['PULocationID'].eq(214)|df['PULocationID'].eq(221)|df['PULocationID'].eq(245)|df['PULocationID'].eq(251),\n",
        "        df['PULocationID'].eq(11)|df['PULocationID'].eq(14)|df['PULocationID'].eq(17)|df['PULocationID'].eq(21)|df['PULocationID'].eq(22)|df['PULocationID'].eq(25)|df['PULocationID'].eq(26)|df['PULocationID'].eq(29)|df['PULocationID'].eq(33)|df['PULocationID'].eq(34)|df['PULocationID'].eq(35)|df['PULocationID'].eq(36)|df['PULocationID'].eq(37)|df['PULocationID'].eq(39)|df['PULocationID'].eq(40)|df['PULocationID'].eq(49)|df['PULocationID'].eq(52)|df['PULocationID'].eq(54)|df['PULocationID'].eq(55)|df['PULocationID'].eq(61)|df['PULocationID'].eq(62)|df['PULocationID'].eq(63)|df['PULocationID'].eq(65)|df['PULocationID'].eq(66)|df['PULocationID'].eq(67)|df['PULocationID'].eq(71)|df['PULocationID'].eq(72)|df['PULocationID'].eq(76)|df['PULocationID'].eq(77)|df['PULocationID'].eq(80)|df['PULocationID'].eq(85)|df['PULocationID'].eq(89)|df['PULocationID'].eq(91)|df['PULocationID'].eq(97)|df['PULocationID'].eq(106)|df['PULocationID'].eq(108)|df['PULocationID'].eq(111)|df['PULocationID'].eq(112)|df['PULocationID'].eq(123)|df['PULocationID'].eq(133)|df['PULocationID'].eq(149)|df['PULocationID'].eq(150)|df['PULocationID'].eq(154)|df['PULocationID'].eq(155)|df['PULocationID'].eq(165)|df['PULocationID'].eq(177)|df['PULocationID'].eq(178)|df['PULocationID'].eq(181)|df['PULocationID'].eq(188)|df['PULocationID'].eq(189)|df['PULocationID'].eq(190)|df['PULocationID'].eq(195)|df['PULocationID'].eq(210)|df['PULocationID'].eq(217)|df['PULocationID'].eq(222)|df['PULocationID'].eq(225)|df['PULocationID'].eq(227)|df['PULocationID'].eq(228)|df['PULocationID'].eq(255)|df['PULocationID'].eq(256)|df['PULocationID'].eq(257),\n",
        "        df['PULocationID'].eq(1)|df['PULocationID'].eq(264)|df['PULocationID'].eq(265)\n",
        "    ]\n",
        "    choices = [\n",
        "        'Queens',\n",
        "        'Bronx',\n",
        "        'Manhattan',\n",
        "        'Staten Island',\n",
        "        'Brooklyn',\n",
        "        np.nan\n",
        "    ]\n",
        "    df['Borough'] = np.select(conditions, choices, df['PULocationID'])\n",
        "    df = df[df['Borough']!='nan']\n",
        "    return df\n",
        "\n",
        "    "
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604902161307
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resample_boroughs_df(df):\n",
        "    # add count column \n",
        "    df['count'] = df['pickup_time'].map(lambda x:1)\n",
        "    # print(df['pickup_time'].value_counts())\n",
        "    # convert to datetime object\n",
        "    df['pickup_time'] = df['pickup_time'].map(lambda x: pd.to_datetime(x, format='%Y-%m-%d %H:%M:%S'))\n",
        "    df = df[['pickup_time', 'count']]\n",
        "\n",
        "    # setting index\n",
        "    df = df.set_index(pd.DatetimeIndex(df['pickup_time']), drop=True)\n",
        "\n",
        "    # Resample by hourly\n",
        "    df = df.resample('H').sum()\n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604902161544
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Create a function that generates borough dataframe that will save it as pickle folder"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#june_2020_df.loc[(june_2020_df['PULocationID'] == 140), :]"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604902161688
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_borough_dfs(df, year, month):\n",
        "    df = df[df['Borough'] != 'nan']\n",
        "    resampled_df = resample_boroughs_df(df)\n",
        "    pickle.dump(resampled_df, open(f'./data/boroughs_df/all_{year}_{month}.pkl','wb'))\n",
        "    print('all borough ts pickled')\n",
        "    man_df = df.loc[(df['Borough'] == 'Manhattan'), :]\n",
        "    staten_df = df.loc[(df['Borough'] == 'Staten Island'), :]\n",
        "    brook_df = df.loc[(df['Borough'] == 'Brooklyn'), :]\n",
        "    bronx_df = df.loc[(df['Borough'] == 'Bronx'), :]\n",
        "    queens_df = df.loc[(df['Borough'] == 'Queens'), :]\n",
        "    boroughs = ['manhattan', 'brooklyn', 'bronx', 'staten', 'queens']\n",
        "    resampled_man_df = resample_boroughs_df(man_df)\n",
        "    resampled_man_df.head()\n",
        "    resampled_brook_df = resample_boroughs_df(brook_df)\n",
        "    resampled_bronx_df = resample_boroughs_df(bronx_df)\n",
        "    resampled_staten_df = resample_boroughs_df(staten_df)\n",
        "    resampled_queens_df = resample_boroughs_df(queens_df)\n",
        "    print('resample process finished')\n",
        "\n",
        "    dfs = [resampled_man_df, resampled_brook_df, resampled_bronx_df, resampled_staten_df, resampled_queens_df]\n",
        "    for i in range(0, 5):\n",
        "        pickle.dump(dfs[i], open(f'./data/boroughs_df/{boroughs[i]}_{year}_{month}.pkl','wb'))\n",
        "    print('resampled boroughs success')\n",
        "\n",
        "    return \n"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604902163732
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Create function that cleans up my dataset"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_pickup_time(dataframe, borough_info, year, month):\n",
        "    # Assign Boroguh\n",
        "    time_df = assign_borough(dataframe, borough_info)\n",
        "    # Subset the pickup time, rename column, and sort\n",
        "    time_df =dataframe[['tpep_pickup_datetime', 'PULocationID','fare_amount','tolls_amount', 'tip_amount', 'total_amount', 'trip_distance', 'Borough']]\n",
        "    time_df = time_df.rename(columns={\"tpep_pickup_datetime\": \"pickup_time\"})\n",
        "    time_df = time_df.sort_values(by='pickup_time')\n",
        "    time_df['pickup_time'] = time_df['pickup_time'].map(lambda x: np.nan if (str(x[0:4])!=year or str(x[5:7]) != month ) else x)\n",
        "    print('missing values before cleaning:', time_df.isna().sum())\n",
        "    time_df.dropna(subset=['pickup_time'], inplace=True)\n",
        "    print('missing values after cleaning:', time_df.isna().sum())\n",
        "    print(time_df.columns)\n",
        "    generate_borough_dfs(time_df, year, month)\n",
        "\n",
        "    #pickle data\n",
        "    pickle.dump(time_df, open(f'./data/pickled/alldata_{year}_{month}.pkl','wb'))\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    print('data cleaning complete!')\n",
        "    # Save csv file to cleaned_data folder\n",
        "    \n",
        "    #pickle data before indexing\n",
        "    pickle.dump(time_df, open(f'./data/pickled/ts_{year}_{month}.pkl','wb'))\n",
        "    return time_df"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604902165108
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### For some reason, our dataset which should only have January 2020 data but starts from 2003, 2008, and ends at 2021 and even months which make no sense. So I will have to drop those rows that are not in 2020 of january. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_jan_2020_df = clean_pickup_time(jan_2020_df, borough_info, '2020', '01')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      212\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604903300346
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_feb_2020_df = clean_pickup_time(feb_2020_df, borough_info, '2020', '02')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      303\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604904678677
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_march_2020_df = clean_pickup_time(march_2020_df, borough_info, '2020', '03')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      426\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "resample process finished\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604785898212
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaned_april_2020_df = clean_pickup_time(april_2020_df, borough_info, '2020', '04')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      132\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "resample process finished\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604785265368
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_may_2020_df = clean_pickup_time(may_2020_df, borough_info, '2020', '05')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      23\n",
            "PULocationID      0\n",
            "fare_amount       0\n",
            "tolls_amount      0\n",
            "tip_amount        0\n",
            "total_amount      0\n",
            "trip_distance     0\n",
            "Borough           0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "resample process finished\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604785158869
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_june_2020_df = clean_pickup_time(june_2020_df, borough_info, '2020', '06')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      9\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "2020-06-10 23:13:00    8\n",
            "2020-06-15 04:44:00    8\n",
            "2020-06-12 04:36:00    8\n",
            "2020-06-22 04:34:00    8\n",
            "2020-06-03 23:52:00    8\n",
            "                      ..\n",
            "2020-06-01 20:29:33    1\n",
            "2020-06-18 16:46:31    1\n",
            "2020-06-21 06:45:46    1\n",
            "2020-06-07 23:49:39    1\n",
            "2020-06-05 23:05:34    1\n",
            "Name: pickup_time, Length: 457543, dtype: int64\n",
            "all borough ts pickled\n",
            "               pickup_time  PULocationID  fare_amount  tolls_amount  \\\n",
            "499366 2020-06-01 00:00:00            75        23.57          0.00   \n",
            "47     2020-06-01 00:00:51            68        15.50          0.00   \n",
            "499345 2020-06-01 00:01:00            75        43.52          6.12   \n",
            "499355 2020-06-01 00:01:00           137        18.74          6.12   \n",
            "135    2020-06-01 00:01:01           152        17.50          0.00   \n",
            "...                    ...           ...          ...           ...   \n",
            "498865 2020-06-30 23:57:42           137         8.50          0.00   \n",
            "549734 2020-06-30 23:58:00           232        15.84          0.00   \n",
            "498809 2020-06-30 23:58:29           230         5.00          0.00   \n",
            "498758 2020-06-30 23:58:38           229         7.00          0.00   \n",
            "498724 2020-06-30 23:58:38            75         5.50          0.00   \n",
            "\n",
            "        tip_amount  total_amount  trip_distance    Borough  count  \n",
            "499366        0.00         26.87           8.65  Manhattan      1  \n",
            "47            3.86         23.16           4.92  Manhattan      1  \n",
            "499345        0.00         50.44          21.65  Manhattan      1  \n",
            "499355        0.00         28.16           6.58  Manhattan      1  \n",
            "135           0.00         21.30           5.39  Manhattan      1  \n",
            "...            ...           ...            ...        ...    ...  \n",
            "498865        0.00         12.30           1.82  Manhattan      1  \n",
            "549734        2.13         21.27           5.55  Manhattan      1  \n",
            "498809        0.00          8.80           0.70  Manhattan      1  \n",
            "498758        3.24         14.04           1.52  Manhattan      1  \n",
            "498724        2.00          8.80           1.16  Manhattan      1  \n",
            "\n",
            "[481227 rows x 9 columns]\n",
            "2020-06-10 23:13:00    7\n",
            "2020-06-25 16:18:00    7\n",
            "2020-06-23 11:06:36    6\n",
            "2020-06-12 23:14:00    6\n",
            "2020-06-25 12:56:00    6\n",
            "                      ..\n",
            "2020-06-01 18:28:02    1\n",
            "2020-06-15 09:52:54    1\n",
            "2020-06-20 01:03:35    1\n",
            "2020-06-03 14:27:58    1\n",
            "2020-06-15 18:16:12    1\n",
            "Name: pickup_time, Length: 413012, dtype: int64\n",
            "2020-06-23 05:03:00    4\n",
            "2020-06-23 11:45:00    4\n",
            "2020-06-03 05:59:00    4\n",
            "2020-06-29 04:41:00    4\n",
            "2020-06-09 04:40:00    4\n",
            "                      ..\n",
            "2020-06-01 21:10:00    1\n",
            "2020-06-18 04:06:00    1\n",
            "2020-06-08 04:39:00    1\n",
            "2020-06-11 05:56:00    1\n",
            "2020-06-25 09:40:00    1\n",
            "Name: pickup_time, Length: 17402, dtype: int64\n",
            "2020-06-11 06:01:00    4\n",
            "2020-06-24 04:47:00    4\n",
            "2020-06-23 04:56:00    3\n",
            "2020-06-09 01:23:00    3\n",
            "2020-06-19 04:52:00    3\n",
            "                      ..\n",
            "2020-06-17 18:21:32    1\n",
            "2020-06-18 03:16:00    1\n",
            "2020-06-26 21:10:48    1\n",
            "2020-06-10 04:28:00    1\n",
            "2020-06-12 17:28:11    1\n",
            "Name: pickup_time, Length: 9649, dtype: int64\n",
            "2020-06-29 21:36:36    2\n",
            "2020-06-18 05:27:00    2\n",
            "2020-06-09 04:00:00    2\n",
            "2020-06-08 05:16:00    2\n",
            "2020-06-22 05:43:00    2\n",
            "                      ..\n",
            "2020-06-19 05:00:23    1\n",
            "2020-06-17 05:22:00    1\n",
            "2020-06-02 01:19:00    1\n",
            "2020-06-07 05:56:00    1\n",
            "2020-06-12 05:28:32    1\n",
            "Name: pickup_time, Length: 540, dtype: int64\n",
            "2020-06-10 04:28:00    4\n",
            "2020-06-27 03:34:00    4\n",
            "2020-06-27 17:20:36    3\n",
            "2020-06-04 05:49:00    3\n",
            "2020-06-12 03:28:00    3\n",
            "                      ..\n",
            "2020-06-18 12:43:56    1\n",
            "2020-06-01 04:08:27    1\n",
            "2020-06-29 10:10:42    1\n",
            "2020-06-18 01:44:49    1\n",
            "2020-06-12 17:28:11    1\n",
            "Name: pickup_time, Length: 33440, dtype: int64\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604809716910
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For the year 2019:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_jan_2019_df = clean_pickup_time(jan_2019_df, borough_info, '2019', '01')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      537\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "resample process finished\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 33,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604789884208
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_feb_2019_df = clean_pickup_time(feb_2019_df, borough_info, '2019', '02')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      625\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "execution_count": 37,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_march_2019_df = clean_pickup_time(march_2019_df, borough_info, '2019', '03')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      510\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604795595345
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_april_2019_df = clean_pickup_time(april_2019_df, borough_info, '2019', '04')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      313\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604797151574
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_may_2019_df = clean_pickup_time(may_2019_df, borough_info, '2019', '05')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      256\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       1\n",
            "tip_amount         0\n",
            "total_amount       1\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     1\n",
            "tip_amount       0\n",
            "total_amount     1\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604801830132
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_june_2019_df = clean_pickup_time(june_2019_df, borough_info, '2019', '06')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      535\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604804225546
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_july_2019_df = clean_pickup_time(july_2019_df, borough_info, '2019', '07')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      285\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604811172770
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_aug_2019_df = clean_pickup_time(august_2019_df, borough_info, '2019', '08')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      506\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604823756161
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_sept_2019_df = clean_pickup_time(september_2019_df, borough_info, '2019', '09')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      392\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604825111429
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_oct_2019_df = clean_pickup_time(october_2019_df, borough_info, '2019', '10')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      303\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604826536308
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_nov_2019_df = clean_pickup_time(november_2019_df, borough_info, '2019', '11')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      648\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 31,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604828634037
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#cleaned_dec_2019_df = clean_pickup_time(december_2019_df, borough_info, '2019', '12')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing values before cleaning: pickup_time      384\n",
            "PULocationID       0\n",
            "fare_amount        0\n",
            "tolls_amount       0\n",
            "tip_amount         0\n",
            "total_amount       0\n",
            "trip_distance      0\n",
            "Borough            0\n",
            "dtype: int64\n",
            "missing values after cleaning: pickup_time      0\n",
            "PULocationID     0\n",
            "fare_amount      0\n",
            "tolls_amount     0\n",
            "tip_amount       0\n",
            "total_amount     0\n",
            "trip_distance    0\n",
            "Borough          0\n",
            "dtype: int64\n",
            "Index(['pickup_time', 'PULocationID', 'fare_amount', 'tolls_amount',\n",
            "       'tip_amount', 'total_amount', 'trip_distance', 'Borough'],\n",
            "      dtype='object')\n",
            "all borough ts pickled\n",
            "resample process finished\n",
            "resampled boroughs success\n",
            "data cleaning complete!\n"
          ]
        }
      ],
      "execution_count": 35,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604832235681
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now that a year worth of data is cleaned up, we would need to merge the cleaned data into one to show one year worth of dataset since it is in time interval of an hour"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assign cleaned data, merge the data and pickle"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Manhattan Data:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_pickle_df(borough):\n",
        "    df_06_19 = pickle.load(open(f'./data/boroughs_df/{borough}_2019_06.pkl','rb'))\n",
        "    df_07_19 = pickle.load(open(f'./data/boroughs_df/{borough}_2019_07.pkl','rb'))\n",
        "    df_08_19 = pickle.load(open(f'./data/boroughs_df/{borough}_2019_08.pkl','rb'))\n",
        "    df_09_19 = pickle.load(open(f'./data/boroughs_df/{borough}_2019_09.pkl','rb'))\n",
        "    df_10_19 = pickle.load(open(f'./data/boroughs_df/{borough}_2019_10.pkl','rb'))\n",
        "    df_11_19 = pickle.load(open(f'./data/boroughs_df/{borough}_2019_11.pkl','rb'))\n",
        "    df_12_19 = pickle.load(open(f'./data/boroughs_df/{borough}_2019_12.pkl','rb'))\n",
        "    df_01_20 = pickle.load(open(f'./data/boroughs_df/{borough}_2020_01.pkl','rb'))\n",
        "    df_02_20 = pickle.load(open(f'./data/boroughs_df/{borough}_2020_02.pkl','rb'))\n",
        "    df_03_20 = pickle.load(open(f'./data/boroughs_df/{borough}_2020_03.pkl','rb'))\n",
        "    df_04_20 = pickle.load(open(f'./data/boroughs_df/{borough}_2020_04.pkl','rb'))\n",
        "    df_05_20 = pickle.load(open(f'./data/boroughs_df/{borough}_2020_05.pkl','rb'))\n",
        "    df_06_20 = pickle.load(open(f'./data/boroughs_df/{borough}_2020_06.pkl','rb'))\n",
        "    list_df = [df_06_19, df_07_19, df_08_19, df_09_19, df_10_19, df_11_19, df_12_19, df_01_20, df_02_20, df_03_20, df_04_20, df_05_20, df_06_20]\n",
        "    borough_df = pd.concat(list_man, axis=0, join='outer', ignore_index=False, keys=None, levels=None, names=None, verify_integrity=False, copy=True)\n",
        "    pickle.dump(manhattan_df, open(f'./data/final_cleaned_data/{borough}_cleaned_data.pkl','wb'))\n",
        "    print(f'pickle completed for {borough}')\n",
        "    return borough_df\n"
      ],
      "outputs": [],
      "execution_count": 64,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604907066491
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Manhattan dataframe:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manhattan_df = merge_pickle_df('manhattan')\n",
        "manhattan_df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pickle completed for manhattan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 65,
          "data": {
            "text/plain": "                     count\npickup_time               \n2019-06-01 00:00:00  10744\n2019-06-01 01:00:00   8371\n2019-06-01 02:00:00   6212\n2019-06-01 03:00:00   4319\n2019-06-01 04:00:00   2921\n...                    ...\n2020-06-30 19:00:00   1130\n2020-06-30 20:00:00    730\n2020-06-30 21:00:00    553\n2020-06-30 22:00:00    466\n2020-06-30 23:00:00    354\n\n[9504 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>pickup_time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-06-01 00:00:00</th>\n      <td>10744</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 01:00:00</th>\n      <td>8371</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 02:00:00</th>\n      <td>6212</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 03:00:00</th>\n      <td>4319</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 04:00:00</th>\n      <td>2921</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 19:00:00</th>\n      <td>1130</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 20:00:00</th>\n      <td>730</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 21:00:00</th>\n      <td>553</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 22:00:00</th>\n      <td>466</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 23:00:00</th>\n      <td>354</td>\n    </tr>\n  </tbody>\n</table>\n<p>9504 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 65,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604907069031
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Queens:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queens_df = merge_pickle_df('queens')\n",
        "queens_df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pickle completed for queens\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 66,
          "data": {
            "text/plain": "                     count\npickup_time               \n2019-06-01 00:00:00  10744\n2019-06-01 01:00:00   8371\n2019-06-01 02:00:00   6212\n2019-06-01 03:00:00   4319\n2019-06-01 04:00:00   2921\n...                    ...\n2020-06-30 19:00:00   1130\n2020-06-30 20:00:00    730\n2020-06-30 21:00:00    553\n2020-06-30 22:00:00    466\n2020-06-30 23:00:00    354\n\n[9504 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>pickup_time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-06-01 00:00:00</th>\n      <td>10744</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 01:00:00</th>\n      <td>8371</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 02:00:00</th>\n      <td>6212</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 03:00:00</th>\n      <td>4319</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 04:00:00</th>\n      <td>2921</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 19:00:00</th>\n      <td>1130</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 20:00:00</th>\n      <td>730</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 21:00:00</th>\n      <td>553</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 22:00:00</th>\n      <td>466</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 23:00:00</th>\n      <td>354</td>\n    </tr>\n  </tbody>\n</table>\n<p>9504 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 66,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604907071539
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For brooklyn"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "brooklyn_df = merge_pickle_df('brooklyn')\n",
        "brooklyn_df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pickle completed for brooklyn\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 67,
          "data": {
            "text/plain": "                     count\npickup_time               \n2019-06-01 00:00:00  10744\n2019-06-01 01:00:00   8371\n2019-06-01 02:00:00   6212\n2019-06-01 03:00:00   4319\n2019-06-01 04:00:00   2921\n...                    ...\n2020-06-30 19:00:00   1130\n2020-06-30 20:00:00    730\n2020-06-30 21:00:00    553\n2020-06-30 22:00:00    466\n2020-06-30 23:00:00    354\n\n[9504 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>pickup_time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-06-01 00:00:00</th>\n      <td>10744</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 01:00:00</th>\n      <td>8371</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 02:00:00</th>\n      <td>6212</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 03:00:00</th>\n      <td>4319</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 04:00:00</th>\n      <td>2921</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 19:00:00</th>\n      <td>1130</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 20:00:00</th>\n      <td>730</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 21:00:00</th>\n      <td>553</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 22:00:00</th>\n      <td>466</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 23:00:00</th>\n      <td>354</td>\n    </tr>\n  </tbody>\n</table>\n<p>9504 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 67,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604907134186
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Bronx:"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bronx_df = merge_pickle_df('bronx')\n",
        "bronx_df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pickle completed for bronx\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 69,
          "data": {
            "text/plain": "                     count\npickup_time               \n2019-06-01 00:00:00  10744\n2019-06-01 01:00:00   8371\n2019-06-01 02:00:00   6212\n2019-06-01 03:00:00   4319\n2019-06-01 04:00:00   2921\n...                    ...\n2020-06-30 19:00:00   1130\n2020-06-30 20:00:00    730\n2020-06-30 21:00:00    553\n2020-06-30 22:00:00    466\n2020-06-30 23:00:00    354\n\n[9504 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>pickup_time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-06-01 00:00:00</th>\n      <td>10744</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 01:00:00</th>\n      <td>8371</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 02:00:00</th>\n      <td>6212</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 03:00:00</th>\n      <td>4319</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 04:00:00</th>\n      <td>2921</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 19:00:00</th>\n      <td>1130</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 20:00:00</th>\n      <td>730</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 21:00:00</th>\n      <td>553</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 22:00:00</th>\n      <td>466</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 23:00:00</th>\n      <td>354</td>\n    </tr>\n  </tbody>\n</table>\n<p>9504 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 69,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604907193029
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### For Staten Island"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "staten_df = merge_pickle_df('staten')\n",
        "staten_df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pickle completed for staten\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 70,
          "data": {
            "text/plain": "                     count\npickup_time               \n2019-06-01 00:00:00  10744\n2019-06-01 01:00:00   8371\n2019-06-01 02:00:00   6212\n2019-06-01 03:00:00   4319\n2019-06-01 04:00:00   2921\n...                    ...\n2020-06-30 19:00:00   1130\n2020-06-30 20:00:00    730\n2020-06-30 21:00:00    553\n2020-06-30 22:00:00    466\n2020-06-30 23:00:00    354\n\n[9504 rows x 1 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>count</th>\n    </tr>\n    <tr>\n      <th>pickup_time</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2019-06-01 00:00:00</th>\n      <td>10744</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 01:00:00</th>\n      <td>8371</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 02:00:00</th>\n      <td>6212</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 03:00:00</th>\n      <td>4319</td>\n    </tr>\n    <tr>\n      <th>2019-06-01 04:00:00</th>\n      <td>2921</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 19:00:00</th>\n      <td>1130</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 20:00:00</th>\n      <td>730</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 21:00:00</th>\n      <td>553</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 22:00:00</th>\n      <td>466</td>\n    </tr>\n    <tr>\n      <th>2020-06-30 23:00:00</th>\n      <td>354</td>\n    </tr>\n  </tbody>\n</table>\n<p>9504 rows × 1 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 70,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1604907223912
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}